{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76990a26",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "### Parsing, cleaning and structuring the journal data\n",
    "### 1. Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050335f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of DataFrame before cleaning: 1299\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "# Download stopwords if not already available\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Path to Excel file\n",
    "file_path = \"../data/raw/daily_sentences.xlsx\"\n",
    "\n",
    "# Read all sheets as a dictionary of DataFrames\n",
    "sheets = pd.read_excel(file_path, sheet_name=None)\n",
    "df_list = []\n",
    "for sheet_name, df in sheets.items():\n",
    "    df[['date', 'sentence']] = df[f'Daily Sentence {sheet_name}'].str.split(' ', n=1, expand=True)\n",
    "    df['date'] = df['date'].astype(str) + '/' + str(sheet_name) # Adds the year to the date\n",
    "    df_list.append(df)\n",
    "\n",
    "# Combine all sheets into one DataFrame\n",
    "df = pd.concat(df_list, ignore_index=True)\n",
    "df = df[['date', 'sentence']] # Reduce columns\n",
    "\n",
    "# Convert 'Date' column to datetime format\n",
    "df['date'] = pd.to_datetime(df['date'], format='%m/%d/%Y', errors='raise')\n",
    "df['sentence'] = df['sentence'].fillna('')\n",
    "df['year'] = df['date'].dt.year\n",
    "df['month'] = df['date'].dt.to_period('M')\n",
    "df['day'] = df['date'].dt.day\n",
    "\n",
    "print(\"Length of DataFrame before cleaning:\", len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4939f23d",
   "metadata": {},
   "source": [
    "### 2. Clean the data\n",
    "Check for duplicates/NaNs - I accidently put '02-26' instead of '03-26' and put '11-27' instead of '11-28'\n",
    "\n",
    "NOTE: This would need to be updated and improved if using on a different dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f199d118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 duplicates found...\n",
      "0 duplicates remaining\n",
      "0 null dates found\n"
     ]
    }
   ],
   "source": [
    "# Error checking for duplicate days and entries\n",
    "duplicates = df[df.duplicated('date', keep=False)]\n",
    "#print(duplicates)\n",
    "\n",
    "if len(duplicates) > 0:\n",
    "    print(f\"{len(duplicates)} duplicates found...\")\n",
    "    # There are two duplicates entires. One has the wrong day and one has the wrong month\n",
    "    df.loc[84, 'date'] = '2025-03-26'\n",
    "    df.loc[922, 'date'] = '2021-11-28'\n",
    "    # Recheck for duplicates\n",
    "    duplicates = df[df.duplicated('date', keep=False)]\n",
    "    print(f\"{len(duplicates)} duplicates remaining\")\n",
    "else:\n",
    "    print(\"No duplicates found\")\n",
    "\n",
    "\n",
    "# Checking for any null dates\n",
    "print(df['date'].isna().sum(), \"null dates found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ba4476",
   "metadata": {},
   "source": [
    "Clean and standardize the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16523935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>sentence</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>cleaned_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>Got back home at like 4 and slept in. Got cava...</td>\n",
       "      <td>2025</td>\n",
       "      <td>2025-01</td>\n",
       "      <td>1</td>\n",
       "      <td>back like 4 slept cava cookies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-01-02</td>\n",
       "      <td>Got taco chinoz and boba with guys and Oscar a...</td>\n",
       "      <td>2025</td>\n",
       "      <td>2025-01</td>\n",
       "      <td>2</td>\n",
       "      <td>taco chinoz boba guys oscar almost folded yurie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-01-03</td>\n",
       "      <td>Got new tires. Started snowing. Got Ko Hyang w...</td>\n",
       "      <td>2025</td>\n",
       "      <td>2025-01</td>\n",
       "      <td>3</td>\n",
       "      <td>new tires started snowing ko hyang yurie mall ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date                                           sentence  year  \\\n",
       "0 2025-01-01  Got back home at like 4 and slept in. Got cava...  2025   \n",
       "1 2025-01-02  Got taco chinoz and boba with guys and Oscar a...  2025   \n",
       "2 2025-01-03  Got new tires. Started snowing. Got Ko Hyang w...  2025   \n",
       "\n",
       "     month  day                                      cleaned_words  \n",
       "0  2025-01    1                     back like 4 slept cava cookies  \n",
       "1  2025-01    2    taco chinoz boba guys oscar almost folded yurie  \n",
       "2  2025-01    3  new tires started snowing ko hyang yurie mall ...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the list of English stop words and add custom ones\n",
    "stop_words = set(stopwords.words('english'))\n",
    "custom_stop_words = {'got', 'went', 'saw', 'made', 'played', 'home', 'drove', 'day', 'took'}\n",
    "stop_words.update(custom_stop_words) \n",
    "\n",
    "pattern = re.compile(r'\\b\\w+\\b')\n",
    "\n",
    "# Function to clean, tokenize, and filter text\n",
    "def tokenize_and_filter(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    words = pattern.findall(text.lower())\n",
    "    return ' '.join([w for w in words if w not in stop_words])\n",
    "\n",
    "\n",
    "df['cleaned_words'] = df['sentence'].apply(tokenize_and_filter)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e59ca99",
   "metadata": {},
   "source": [
    "Another variation of cleaned text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "517960cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacobchang/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\", \"parser\"])\n",
    "\n",
    "def clean_with_spacy(text):\n",
    "    doc = nlp(text.lower())\n",
    "    tokens = [token.lemma_ for token in doc \n",
    "              if not token.is_stop and token.is_alpha]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "df['cleaned_words2'] = df['sentence'].astype(str).apply(clean_with_spacy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bded8c85",
   "metadata": {},
   "source": [
    "Output the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff2f8406",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"../data/cleaned/daily_sentences_cleaned.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
